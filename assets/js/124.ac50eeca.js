(window.webpackJsonp=window.webpackJsonp||[]).push([[124],{520:function(s,t,a){"use strict";a.r(t);var e=a(56),n=Object(e.a)({},(function(){var s=this,t=s.$createElement,a=s._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[a("h1",{attrs:{id:"面试官-单线程的redis为什么能支持10w-的qps"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#面试官-单线程的redis为什么能支持10w-的qps"}},[s._v("#")]),s._v(" 面试官：单线程的Redis为什么能支持10w+的QPS?")]),s._v(" "),a("p",[a("img",{attrs:{src:"https://img-blog.csdnimg.cn/20210130141613187.jpg?",alt:"在这里插入图片描述"}})]),s._v(" "),a("h2",{attrs:{id:"单线程为什么能支持10w-的qps"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#单线程为什么能支持10w-的qps"}},[s._v("#")]),s._v(" 单线程为什么能支持10w+的QPS？")]),s._v(" "),a("p",[s._v("我们经常听到Redis是一个单线程程序。准确的说Redis是一个多线程程序，只不过请求处理的部分是用一个线程来实现的。")]),s._v(" "),a("p",[s._v("阿里云对Redis QPS的测试结果如下所示\n"),a("img",{attrs:{src:"https://img-blog.csdnimg.cn/2021022721212118.png?",alt:"在这里插入图片描述"}}),s._v(" "),a("strong",[s._v("Redis是如何用单线程来实现每秒10w+的QPS的呢？")])]),s._v(" "),a("ol",[a("li",[s._v("使用IO多路复用")]),s._v(" "),a("li",[s._v("非CPU密集型任务")]),s._v(" "),a("li",[s._v("纯内存操作")]),s._v(" "),a("li",[s._v("高效的数据结构")])]),s._v(" "),a("p",[a("strong",[s._v("只用一个线程怎么来处理多个客户端的连接呢？")])]),s._v(" "),a("p",[s._v("这就不得不提IO多路复用技术，即Java中的NIO。")]),s._v(" "),a("p",[s._v("当我们使用阻塞IO（Java中的BIO），调用read函数，传入参数n，表示读取n个字节后线程才会返回，不然就一直阻塞。write方法一般不会阻塞，除非写缓冲区被写满，write才会被阻塞，直到缓冲区中有空间被释放出来。")]),s._v(" "),a("p",[s._v("当我们使用IO多路复用技术时，当没有数据可读或者可写，客户端线程会直接返回，并不会阻塞。这样Redis就可以用一个线程来监听多个Socket，当一个Socket可读或可写的时候，Redis去读取请求，操作内存中数据，然后返回。")]),s._v(" "),a("p",[a("strong",[s._v("当采用单线程时，就无法使用多核CPU，但Redis中大部分命令都不是CPU密集型任务，所以CPU并不是Redis的瓶颈")]),s._v("。")]),s._v(" "),a("p",[s._v("高并发和大数据量的请宽下Redis的瓶颈主要体现在内存和网络带宽，所以你看Redis为了节省内存，在底层数据结构上占用的内存能少就少，并且一种类型的数据在不同的场景下会采用不同的数据结构。")]),s._v(" "),a("p",[a("img",{attrs:{src:"https://img-blog.csdnimg.cn/20210130140038568.png?",alt:"在这里插入图片描述"}})]),s._v(" "),a("p",[a("strong",[s._v("所以Redis采用单线程就已经能处理海量的请求，因此就没必要使用多线程")]),s._v("。除此之外，"),a("strong",[s._v("使用单线程还有如下好处")])]),s._v(" "),a("ol",[a("li",[s._v("没有了线程切换的性能开销")]),s._v(" "),a("li",[s._v("各种操作不用加锁（如果采用多线程，则对共享资源的访问需要加锁，增加开销）")]),s._v(" "),a("li",[s._v("方便调试，可维护性高")])]),s._v(" "),a("p",[a("strong",[s._v("最后Redis是一个内存数据库，各种命令的读写操作都是基于内存完成的")]),s._v("。大家都知道操作内存和操作磁盘效率相差好几个数量级。虽然Redis的效率很高，但还是有一些慢操作需要大家避免")]),s._v(" "),a("h2",{attrs:{id:"redis有哪些慢操作"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#redis有哪些慢操作"}},[s._v("#")]),s._v(" Redis有哪些慢操作？")]),s._v(" "),a("p",[a("img",{attrs:{src:"https://img-blog.csdnimg.cn/20210130154650489.png",alt:"在这里插入图片描述"}}),s._v("\nRedis的各种命令是在一个线程中依次执行的，如果一个命令在Redis中执行的时间过长，就会影响整体的性能，因为后面的请求要等到前面的请求被处理完才能被处理，这些耗时的操作有如下几个部分")]),s._v(" "),a("p",[s._v("Redis可以通过日志记录那些耗时长的命令，使用如下配置即可")]),s._v(" "),a("div",{staticClass:"language-conf extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[s._v("# 命令执行耗时超过 5 毫秒，记录慢日志\nCONFIG SET slowlog-log-slower-than 5000\n# 只保留最近 500 条慢日志\nCONFIG SET slowlog-max-len 500\n")])])]),a("p",[s._v("执行如下命令，就可以查询到最近记录的慢日志")]),s._v(" "),a("div",{staticClass:"language-c extra-class"},[a("pre",{pre:!0,attrs:{class:"language-c"}},[a("code",[a("span",{pre:!0,attrs:{class:"token number"}},[s._v("127.0")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v(".0")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v(".1")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("6379")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" SLOWLOG get "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("integer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("32693")]),s._v("       # 慢日志ID\n   "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("integer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1593763337")]),s._v("  # 执行时间戳\n   "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("integer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5299")]),s._v("        # 执行耗时"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("微秒"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"LRANGE"')]),s._v("           # 具体执行的命令和参数\n      "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"user_list:2000"')]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"0"')]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"-1"')]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("integer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("32692")]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("integer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1593763337")]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("integer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5044")]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"GET"')]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"user_info:1000"')]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n")])])]),a("h3",{attrs:{id:"使用复杂度过高的命令"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#使用复杂度过高的命令"}},[s._v("#")]),s._v(" 使用复杂度过高的命令")]),s._v(" "),a("p",[s._v("之前的文章我们已经介绍了Redis的底层数据结构，它们的时间复杂度如下表所示")]),s._v(" "),a("table",[a("thead",[a("tr",[a("th",[s._v("名称")]),s._v(" "),a("th",[s._v("时间复杂度")])])]),s._v(" "),a("tbody",[a("tr",[a("td",[s._v("dict（字典）")]),s._v(" "),a("td",[s._v("O(1)")])]),s._v(" "),a("tr",[a("td",[s._v("ziplist （压缩列表）")]),s._v(" "),a("td",[s._v("O(n)")])]),s._v(" "),a("tr",[a("td",[s._v("zskiplist （跳表）")]),s._v(" "),a("td",[s._v("O(logN)")])]),s._v(" "),a("tr",[a("td",[s._v("quicklist（快速列表）")]),s._v(" "),a("td",[s._v("O(n)")])]),s._v(" "),a("tr",[a("td",[s._v("intset（整数集合）")]),s._v(" "),a("td",[s._v("O(n)")])])])]),s._v(" "),a("p",[a("strong",[s._v("单元素操作")]),s._v("：对集合中的元素进行增删改查操作和底层数据结构相关，如对字典进行增删改查时间复杂度为O(1)，对跳表进行增删查时间复杂为O(logN)")]),s._v(" "),a("p",[a("strong",[s._v("范围操作")]),s._v("：对集合进行遍历操作，比如Hash类型的HGETALL，Set类型的SMEMBERS，List类型的LRANGE，ZSet类型的ZRANGE，时间复杂度为O(n)，避免使用，用SCAN系列命令代替。（hash用hscan，set用sscan，zset用zscan）")]),s._v(" "),a("p",[a("strong",[s._v("聚合操作")]),s._v("：这类操作的时间复杂度通常大于O(n)，比如SORT、SUNION、ZUNIONSTORE")]),s._v(" "),a("p",[a("strong",[s._v("统计操作")]),s._v("：当想获取集合中的元素个数时，如LLEN或者SCARD，时间复杂度为O(1)，因为它们的底层数据结构如quicklist，dict，intset保存了元素的个数")]),s._v(" "),a("p",[a("strong",[s._v("边界操作")]),s._v("：list底层是用quicklist实现的，quicklist保存了链表的头尾节点，因此对链表的头尾节点进行操作，时间复杂度为O(1)，如LPOP、RPOP、LPUSH、RPUSH")]),s._v(" "),a("p",[a("strong",[s._v("当想获取Redis中的key时，避免使用keys *")]),s._v(" ，Redis中保存的键值对是保存在一个字典中的（和Java中的HashMap类似，也是通过数组+链表的方式实现的），key的类型都是string，value的类型可以是string，set，list等")]),s._v(" "),a("p",[s._v("例如当我们执行如下命令后，redis的字典结构如下")]),s._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("set")]),s._v(" bookName redis"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\nrpush fruits banana apple"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),a("p",[a("img",{attrs:{src:"https://img-blog.csdnimg.cn/20210116155453782.png?",alt:"在这里插入图片描述"}}),s._v("\n我们可以用keys命令来查询Redis中特定的key，如下所示")]),s._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 查询所有的key")]),s._v("\nkeys *\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 查询以book为前缀的key")]),s._v("\nkeys book*\n")])])]),a("p",[s._v("keys命令的复杂度是O(n)，它会遍历这个dict中的所有key，如果Redis中存的key非常多，所有读写Redis的指令都会被延迟等待，所以千万不用在生产环境用这个命令（如果你已经准备离职的话，祝你玩的开心）。")]),s._v(" "),a("p",[a("strong",[s._v("既然不让你用keys，肯定有替代品，那就是scan")])]),s._v(" "),a("p",[s._v("scan和keys相比，有如下特点")]),s._v(" "),a("ol",[a("li",[s._v("复杂虽然也是O(n)，但是是通过游标分布执行的，不会阻塞线程")]),s._v(" "),a("li",[s._v("同keys一样，提供模式匹配功能")]),s._v(" "),a("li",[s._v("从完整遍历开始到完整遍历结束，一直存在于数据集内的所有元素都会被完整遍历返回，但是同一个元素可能会被返回多次")]),s._v(" "),a("li",[s._v("如果一个元素是在迭代过程中被添加到数据集的，或者在迭代过程中从数据集中被删除的，那么这个元素可能会被返回，也可能不会被返回")]),s._v(" "),a("li",[s._v("返回结果为空并不意味着遍历结束，而要看返回的游标值是否为0")])]),s._v(" "),a("p",[s._v("有兴趣的小伙伴可以分析一下scan源码的实现就能明白这些特性了")]),s._v(" "),a("p",[a("strong",[s._v("用用zscan遍历zset，hscan遍历hash，sscan遍历set的原理和scan命令类似，因为hash，set，zset的底层实现的数据结构中都有dict。")])]),s._v(" "),a("h3",{attrs:{id:"操作bigkey"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#操作bigkey"}},[s._v("#")]),s._v(" 操作bigkey")]),s._v(" "),a("p",[a("strong",[s._v("如果一个key对应的value非常大，那么这个key就被称为bigkey。写入bigkey在分配内存时需要消耗更长的时间。同样，删除bigkey释放内存也需要消耗更长的时间")])]),s._v(" "),a("p",[s._v("如果在慢日志中发现了SET/DEL这种复杂度不高的命令，此时你就应该排查一下是否是由于写入bigkey导致的。")]),s._v(" "),a("p",[a("strong",[s._v("如何定位bigkey?")])]),s._v(" "),a("p",[s._v("Redis提供了扫描bigkey的命令")]),s._v(" "),a("div",{staticClass:"language-c extra-class"},[a("pre",{pre:!0,attrs:{class:"language-c"}},[a("code",[s._v("$ redis"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("cli "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("h "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("127.0")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v(".0")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v(".1")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("p "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("6379")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("--")]),s._v("bigkeys "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("i "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.01")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("--")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("--")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("--")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("--")]),s._v(" summary "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("--")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("--")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("--")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("\n\nSampled "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("829675")]),s._v(" keys in the keyspace"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!")]),s._v("\nTotal key length in bytes is "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("10059825")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("avg len "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("12.13")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\nBiggest string found "),a("span",{pre:!0,attrs:{class:"token char"}},[s._v("'key:291880'")]),s._v(" has "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),s._v(" bytes\nBiggest   list found "),a("span",{pre:!0,attrs:{class:"token char"}},[s._v("'mylist:004'")]),s._v(" has "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("40")]),s._v(" items\nBiggest    set found "),a("span",{pre:!0,attrs:{class:"token char"}},[s._v("'myset:2386'")]),s._v(" has "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("38")]),s._v(" members\nBiggest   hash found "),a("span",{pre:!0,attrs:{class:"token char"}},[s._v("'myhash:3574'")]),s._v(" has "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("37")]),s._v(" fields\nBiggest   zset found "),a("span",{pre:!0,attrs:{class:"token char"}},[s._v("'myzset:2704'")]),s._v(" has "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("42")]),s._v(" members\n\n"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("36313")]),s._v(" strings with "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("363130")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("bytes")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("04.38")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("%")]),s._v(" of keys"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" avg size "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("10.00")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("787393")]),s._v(" lists with "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("896540")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("items")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("94.90")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("%")]),s._v(" of keys"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" avg size "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.14")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1994")]),s._v(" sets with "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("40052")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("members")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("00.24")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("%")]),s._v(" of keys"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" avg size "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("20.09")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1990")]),s._v(" hashs with "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("39632")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("fields")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("00.24")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("%")]),s._v(" of keys"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" avg size "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("19.92")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1985")]),s._v(" zsets with "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("39750")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("members")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("00.24")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("%")]),s._v(" of keys"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" avg size "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("20.03")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])])]),a("p",[s._v("可以看到命令的输入有如下3个部分")]),s._v(" "),a("ol",[a("li",[s._v("内存中key的数量，已经占用的总内存，每个key占用的平均内存")]),s._v(" "),a("li",[s._v("每种类型占用的最大内存，已经key的名字")]),s._v(" "),a("li",[s._v("每种数据类型的占比，以及平均大小")])]),s._v(" "),a("p",[s._v("这个命令的原理就是redis在内部执行了scan命令，遍历实例中所有的key，然后正对key的类型，分别执行strlen，llen，hlen，scard，zcard命令，来获取string类型的长度，容器类型（list，hash，set，zset）的元素个数")]),s._v(" "),a("p",[s._v("使用这个命令需要注意如下两个问题")]),s._v(" "),a("ol",[a("li",[s._v("对线上实例进行bigkey扫描时，为避免ops（operation per second 每秒操作次数）突增，可以通过-i增加一个休眠参数，上面的含义为，每隔100条scan指令就会休眠0.01s")]),s._v(" "),a("li",[s._v("对于容器类型（list，hash，set，zset），扫描出的是元素最多的key，但一个key的元素数量多，不一定代表占用的内存多")])]),s._v(" "),a("p",[a("strong",[s._v("如何解决bigkey带来的性能问题？")])]),s._v(" "),a("ol",[a("li",[s._v("尽量避免写入bigkey")]),s._v(" "),a("li",[s._v("如果使用的是redis4.0以上版本，可以用unlink命令代替del，此命令可以把释放key内存的操作，放到后台线程中去执行")]),s._v(" "),a("li",[s._v("如果使用的是redis6.0以上版本，可以开启lazy-free机制（lazyfree-lazy-user-del yes），执行del命令的时候，也会放到后台线程中去执行")])]),s._v(" "),a("h3",{attrs:{id:"大量key集中过期"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#大量key集中过期"}},[s._v("#")]),s._v(" 大量key集中过期")]),s._v(" "),a("p",[s._v("我们可以给Redis中的key设置过期时间，那么当key过期了，它在什么时候会被删除呢？")]),s._v(" "),a("p",[a("strong",[s._v("如果让我们写Redis过期策略，我们会想到如下三种方案")])]),s._v(" "),a("ol",[a("li",[s._v("定时删除，在设置键的过期时间的同时，创建一个定时器。当键的过期时间来临时，立即执行对键的删除操作")]),s._v(" "),a("li",[s._v("惰性删除，每次获取键的时候，判断键是否过期，如果过期的话，就删除该键，如果没有过期，则返回该键")]),s._v(" "),a("li",[s._v("定期删除，每隔一段时间，对键进行一次检查，删除里面的过期键\n定时删除策略对CPU不友好，当过期键比较多的时候，Redis线程用来删除过期键，会影响正常请求的响应")])]),s._v(" "),a("p",[s._v("定时删除策略对CPU不友好，当过期键比较多的时候，Redis线程用来删除过期键，会影响正常请求的响应")]),s._v(" "),a("p",[s._v("惰性删除读CPU是比较有好的，但是会浪费大量的内存。如果一个key设置过期时间放到内存中，但是没有被访问到，那么它会一直存在内存中")]),s._v(" "),a("p",[s._v("定期删除策略则对CPU和内存都比较友好")]),s._v(" "),a("p",[s._v("redis过期key的删除策略选择了如下两种")]),s._v(" "),a("ol",[a("li",[s._v("惰性删除")]),s._v(" "),a("li",[s._v("定期删除")])]),s._v(" "),a("p",[a("strong",[s._v("惰性删除")]),s._v("\n客户端在访问key的时候，对key的过期时间进行校验，如果过期了就立即删除")]),s._v(" "),a("p",[a("strong",[s._v("定期删除")]),s._v("\nRedis会将设置了过期时间的key放在一个独立的字典中，定时遍历这个字典来删除过期的key，遍历策略如下")]),s._v(" "),a("ol",[a("li",[s._v("每秒进行10次过期扫描，每次从过期字典中随机选出20个key")]),s._v(" "),a("li",[s._v("删除20个key中已经过期的key")]),s._v(" "),a("li",[s._v("如果过期key的比例超过1/4，则进行步骤一")]),s._v(" "),a("li",[s._v("每次扫描时间的上限默认不超过25ms，避免线程卡死")])]),s._v(" "),a("p",[a("strong",[s._v("因为Redis中过期的key是由主线程删除的，为了不阻塞用户的请求，所以删除过期key的时候是少量多次")]),s._v("。源码可以参考expire.c中的activeExpireCycle方法")]),s._v(" "),a("p",[s._v("为了避免主线程一直在删除key，我们可以采用如下两种方案")]),s._v(" "),a("ol",[a("li",[s._v("给同时过期的key增加一个随机数，打散过期时间，降低清除key的压力")]),s._v(" "),a("li",[s._v("如果你使用的是redis4.0版本以上的redis，可以开启lazy-free机制（lazyfree-lazy-expire yes），当删除过期key时，把释放内存的操作放到后台线程中执行")])]),s._v(" "),a("h3",{attrs:{id:"内存达到上限-触发淘汰策略"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#内存达到上限-触发淘汰策略"}},[s._v("#")]),s._v(" 内存达到上限，触发淘汰策略")]),s._v(" "),a("p",[a("img",{attrs:{src:"https://img-blog.csdnimg.cn/20210130162350771.png?",alt:"在这里插入图片描述"}}),s._v("\nRedis是一个内存数据库，当Redis使用的内存超过物理内存的限制后，内存数据会和磁盘产生频繁的交换，交换会导致Redis性能急剧下降。所以在生产环境中我们通过配置参数maxmemoey来限制使用的内存大小。")]),s._v(" "),a("p",[s._v("当实际使用的内存超过maxmemoey后，Redis提供了如下几种可选策略。")]),s._v(" "),a("p",[s._v("noeviction：写请求返回错误")]),s._v(" "),a("p",[s._v("volatile-lru：使用lru算法删除设置了过期时间的键值对\nvolatile-lfu：使用lfu算法删除设置了过期时间的键值对\nvolatile-random：在设置了过期时间的键值对中随机进行删除\nvolatile-ttl：根据过期时间的先后进行删除，越早过期的越先被删除")]),s._v(" "),a("p",[s._v("allkeys-lru：在所有键值对中，使用lru算法进行删除\nallkeys-lfu：在所有键值对中，使用lfu算法进行删除\nallkeys-random：所有键值对中随机删除")]),s._v(" "),a("p",[a("strong",[s._v("Redis的淘汰策略也是在主线程中执行的。但内存超过Redis上限后，每次写入都需要淘汰一些key，导致请求时间变长")])]),s._v(" "),a("p",[s._v("可以通过如下几个方式进行改善")]),s._v(" "),a("ol",[a("li",[s._v("增加内存或者将数据放到多个实例中")]),s._v(" "),a("li",[s._v("淘汰策略改为随机淘汰，一般来说随机淘汰比lru快很多")]),s._v(" "),a("li",[s._v("避免存储bigkey，降低释放内存的耗时")])]),s._v(" "),a("h3",{attrs:{id:"写aof日志的方式为always"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#写aof日志的方式为always"}},[s._v("#")]),s._v(" 写AOF日志的方式为always")]),s._v(" "),a("p",[a("img",{attrs:{src:"https://img-blog.csdnimg.cn/20210130163842737.png?",alt:"在这里插入图片描述"}}),s._v("\nRedis的持久化机制有RDB快照和AOF日志，每次写命令之后后，Redis提供了如下三种刷盘机制")]),s._v(" "),a("p",[s._v("always：同步写回，写命令执行完就同步到磁盘\neverysec：每秒写回，每个写命令执行完，只是先把日志写到aof文件的内存缓冲区，每隔1秒将缓冲区的内容写入磁盘\nno：操作系统控制写回，每个写命令执行完，只是先把日志写到aof文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回到磁盘")]),s._v(" "),a("p",[s._v("当aof的刷盘机制为always，redis每处理一次写命令，都会把写命令刷到磁盘中才返回，整个过程是在Redis主线程中进行的，势必会拖慢redis的性能")]),s._v(" "),a("p",[s._v("当aof的刷盘机制为everysec，redis写完内存后就返回，刷盘操作是放到后台线程中去执行的，后台线程每隔1秒把内存中的数据刷到磁盘中")]),s._v(" "),a("p",[s._v("当aof的刷盘机制为no，宕机后可能会造成部分数据丢失，一般不采用。")]),s._v(" "),a("p",[a("strong",[s._v("一般情况下，aof刷盘机制配置为everysec即可")])]),s._v(" "),a("h3",{attrs:{id:"fork耗时过长"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#fork耗时过长"}},[s._v("#")]),s._v(" fork耗时过长")]),s._v(" "),a("p",[s._v("在持久化一节中，我们已经提到"),a("strong",[s._v("Redis生成rdb文件和aof日志重写，都是通过主线程fork子进程的方式，让子进程来执行的，主线程的内存越大，阻塞时间越长。")])]),s._v(" "),a("p",[s._v("可以通过如下方式优化")]),s._v(" "),a("ol",[a("li",[s._v("控制Redis实例的内存大小，尽量控制到10g以内，因")]),s._v(" "),a("li",[s._v("为内存越大，阻塞时间越长")]),s._v(" "),a("li",[s._v("配置合理的持久化策略，如在slave节点生成rdb快照")])])])}),[],!1,null,null,null);t.default=n.exports}}]);